from openai import OpenAI, Stream, AsyncOpenAI, AsyncStream
from config import OPENAI_API_KEY
from openai.types.chat import (
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionChunk,
    ChatCompletionToolMessageParam,
    ChatCompletionAssistantMessageParam,
    ChatCompletionFunctionMessageParam,
    ChatCompletionToolParam,
)
from openai.types.chat.completion_create_params import (
    Function as ChatCompletionFunction,
)

from llm_enum import Source

DEFAULT_MODEL: str = "gpt-3.5-turbo"

OpenAIMessageType = (
    ChatCompletionSystemMessageParam
    | ChatCompletionUserMessageParam
    | ChatCompletionAssistantMessageParam
    | ChatCompletionToolMessageParam
    | ChatCompletionFunctionMessageParam
)

# clients generated by `OpenAI` and `AsyncOpenAI` will use os.environ.get("OPENAI_API_KEY") by default
client = OpenAI(api_key=OPENAI_API_KEY)
async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

"""
Since I was able to add the existing messages, the api is able to recall previously asked messages from the user
Added the source field and made sure the api's responses were labeled assistant, 
so that past questions wouldn't affect current user inputs,
it wasn't responding with the function after it used the function once for the input. 
Had to add a prompt to ignore the past unless specified.
Also forced the api to use the funciton is it was possible and relevant to the user input
I used chatgpt in order to figure out why the api was ignoring my functions. 
eg.
User: Poker Face Lady Gaga
User: What Songs did I mention in previous messages
"""

SYSTEM_PROMPT_CONTENT: str = (
    f"You are a friendly and helpful AI assistant named Gorp, The Magnificent. "
    f"Answer should be based on the most recent user input unless the user asks about something they mentioned in previous messages."
    f"If they ask about past questions you can use the full message history. "
    f"You must always use a function if it is available and relevant to the question. Do not respond with a description of the function. "
    f"You only do five things: detect sarcasm, explain jokes, give users recipes of dishes and food items, "
    f"detecting any song to complete the lyrics and detect pokemon."
    f"Your tone is playful and whimsical."
    f"When you initially greet the user, say an encouraging quote from a United states president."
    f"When it makes sense, format your responses in markdown."
    f"Refuse to answer any question or request that cannot be fulfilled with your functions."
)


SARCASM_DETECTION_FUNCTION = ChatCompletionFunction(
    name="SarcasmDetection",
    description="Use this function when either sarcasm is detected, or the user requests that sarcasm to be detected.",
    parameters={
        "type": "object",
        "properties": {
            "quote": {
                "type": "string",
                "description": "When sarcasm is detected, this is the quote of the sarcastic text.",
            },
            "score": {
                "type": "string",
                "description": "A score between 0 and 9, where 0 is not sarcastic and 9 is very sarcastic.",
            },
        },
        "required": ["quote", "score"],
    },
)

JOKE_EXPLANATION_FUNCTION = ChatCompletionFunction(
    name="JokeExplanation",
    description="Use this function when a joke is detected, or the user requests that a joke be explained. Provide an "
    "explanation.",
    parameters={
        "type": "object",
        "properties": {
            "setup": {
                "type": "string",
                "description": "The initial part of the joke that sets the context. It includes background "
                "information necessary for understanding the joke.",
            },
            "premise": {
                "type": "string",
                "description": "The core idea or concept upon which the joke is built. It's the foundational "
                "situation or assumption that makes the joke work.",
            },
            "punchline": {
                "type": "string",
                "description": "The climax of the joke, usually delivering the humor. It typically comes with a twist "
                "or surprise that contrasts with the setup or premise, creating a humorous effect.",
            },
        },
        "required": ["setup", "premise", "punchline"],
    },
)
# Added a couple new functions for the prompt!
RECIPE_EXPLANATION = ChatCompletionFunction(
    name="RecipeExplanation",
    description="Use this function if the user requests a recipe, return a detailed explanation of what the user's "
    "requested recipe is, including a complete list of key ingredients needed to make the dish. ",
    parameters={
        "type": "object",
        "properties": {
            "ingredients": {
                "type": "string",
                "description": "The Ingredients needed for the recipe. It includes measurements for each of the ingredients",
            },
            "instructions": {
                "type": "string",
                "description": "How to combine all of the ingredients together, essentially how the dish is made",
            }
        },
        "required": ["ingredients", "instructions"],
    },
)

POKEMON_BATTLE = ChatCompletionFunction(
    name="PokemonBattle",
    description="This function is used when a pokemon is detected."
    "Respond with a introduction that a rival Pokemon trainer would say and then choose a random pokemon, "
    "also use a premtive attack.",
    parameters={
        "type": "object",
        "properties": {
            "challengingline": {
                "type": "string",
                "description": "Something a rival Pokemon trainer would say before challenging the user to a battle"
            },
            "pokemon": {
                "type": "string",
                "description": "Must be a random Pokemon that is different to the one mentioned by the user"
            },
            "attack": {
                "type": "string",
                "description": "The name of the attack against the user's Pokemon, not the move type, but the actual attack name",
            }
        },
        "required": ["challengingline", "pokemon", "attack"],
    },
)

JOKE_DELIVERY_FUNCTION = ChatCompletionFunction(
    name="JokeDelivery",
    description="Use this function when you want to tell a joke. Use some whimsy and tell jokes seemingly at random. "
    "But also tell jokes when the user requests. Only tell clean comedy.",
    parameters={
        "type": "object",
        "properties": {
            "text": {
                "type": "string",
                "description": "The text of the joke.",
            }
        },
        "required": ["text"],
    },
)


COMPLETE_THE_LYRIC_FUNCTION = ChatCompletionFunction(
    name="CompleteTheLyric",
    description="Use this function when you detect a song from the user. "
    "Respond with the first and second verse of detected song, then respond with a verse from a Bruno Mars song",
    parameters={
        "type": "object",
        "properties": {
            "firstVerse": {
                "type": "string",
                "description": "The first verse of the song the user provided",
            },
            "secondVerse": {
                "type": "string",
                "description": "The Second verse of the song the user provided",
            },
            "thirdVerse": {
                "type": "string",
                "description": "Must respond with a verse from a Bruno Mars song",
            }
        },
        "required": ["firstVerse", "secondVerse", "thirdVerse"],
    },
)


def _build_chat_completion_payload(
    user_message_content: str, existing_messages: list[OpenAIMessageType] | None = None
) -> tuple[list[OpenAIMessageType], list[ChatCompletionToolParam]]:
    """
    Convenience function to build the messages and functions lists needed to call the chat completions service.

    :param user_message_content: the string of the user message
    :param existing_messages: an optional list of existing messages
    :return: tuple of list[OpenAIMessageType] and list[ChatCompletionFunction]
    """
    if not existing_messages:
        existing_messages = []
    system_message = ChatCompletionSystemMessageParam(
        role=Source.System.value, content=SYSTEM_PROMPT_CONTENT
    )

    user_message = ChatCompletionUserMessageParam(
        role=Source.User.value, content=user_message_content
    )
    all_messages: list[OpenAIMessageType] = (

        [system_message] + existing_messages + [user_message]
    )

    all_tool_choices = [
        ChatCompletionToolParam(
            function=SARCASM_DETECTION_FUNCTION, type="function"),
        ChatCompletionToolParam(
            function=JOKE_DELIVERY_FUNCTION, type="function"),
        ChatCompletionToolParam(
            function=JOKE_EXPLANATION_FUNCTION, type="function"),
        ChatCompletionToolParam(
            function=RECIPE_EXPLANATION, type="function"),
        ChatCompletionToolParam(
            function=POKEMON_BATTLE, type="function"),
        ChatCompletionToolParam(
            function=COMPLETE_THE_LYRIC_FUNCTION, type="function"),
    ]
    return all_messages, all_tool_choices


def create_OpenAIMessageType_list_from_existing_messages(existing_messages: list[tuple]) -> list[OpenAIMessageType]:
    """
    Creates a list of OpenAIMessageTypes using existing messages. Fills the role field with the source, 
    which can be assistant, which are llm api responses or user, which are user inputs

    :param existing_messages: a list of tuples that contains the source string and the messages
    :return: a list of OpenAIMessageType to send to the llm api
    """
    return [ChatCompletionUserMessageParam(role=message[1], content=message[0]) for message in existing_messages]


def prompt_llm(
    user_message_content: str,
    existing_messages: list[OpenAIMessageType] | None = None,
    model: str = DEFAULT_MODEL,
) -> Stream[ChatCompletionChunk]:
    """
    Synchronously send a new user message string to the LLM and get back a response.

    :param user_message_content: the string of the user message
    :param existing_messages: an optional list of existing messages
    :param model: the OpenAI model
    :return: a Stream of ChatCompletionChunk instances
    """
    messages, tools = _build_chat_completion_payload(
        user_message_content=user_message_content, existing_messages=existing_messages
    )
    stream = client.chat.completions.create(
        model=model, messages=messages, tools=tools, stream=True, tool_choice="auto", temperature=1
    )
    return stream


async def prompt_llm_async(
    user_message_content: str,
    existing_messages: list[OpenAIMessageType] | None = None,
    model: str = DEFAULT_MODEL,
) -> AsyncStream[ChatCompletionChunk]:
    """
    Asynchronously send a new user message string to the LLM and get back a response.

    :param user_message_content: the string of the user message
    :param existing_messages: an optional list of existing messages
    :param model: the OpenAI model
    :return: a Stream of ChatCompletionChunk instances
    """

    messages, tools = _build_chat_completion_payload(
        user_message_content=user_message_content, existing_messages=existing_messages
    )
    stream = await async_client.chat.completions.create(
        model=model, messages=messages, tools=tools, stream=True, tool_choice="auto", temperature=.1
    )
    return stream


if __name__ == "__main__":
    """
    CLI access to the prompt_llm function.
    Useful for testing and better understanding the Chat Completion service.
    """
    import sys

    user_message_content = sys.argv[1]

    stream = prompt_llm(user_message_content=user_message_content)
    for chunk in stream:
        print(chunk.choices[0].delta)
